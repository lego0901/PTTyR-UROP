
\documentclass{article}

\usepackage{pttyr_descriptions}


\begin{document}

\setlist{nolistsep}
\nointerlineskip
\par\noindent
\setlength{\parindent}{0pt}

\section*{Matmul Layers}
\subsection*{\texttt{torch.nn.Linear}}
\prepostc{torch.nn.Linear(in\_features, out\_features, bias=True)(x)}{
  \includegraphics[height=12em]{resources/conv2d.png}
}{
  \begin{itemizec}
    \item $|x| = (d_1, d_2, \dots, d_k)$
    \item $\op{rank}{|x|} \geq 1$
    \item $d_k = in\_features$
  \end{itemizec}
}{
  \begin{itemizec}
    \item $|y| = (d_1, d_2, \dots, d_{k-1}, out\_features)$
  \end{itemizec}
}{
  \begin{itemizec}
    \item $y = x A^T + b$를 계산하는 dense 레이어
    \item $1$차원인 경우에도 잘 작동합니다.
    \item $bias$ 옵션은 출력 shape에 영향을 주지 않습니다.
  \end{itemizec}
}
\begin{align*}
  \frac
  {
    \begin{array}{l}
      \sigma \vdash E \Rar e, c \\
      e' = e[1:k-1] \conc (out) \\
      c' = \{ (\op{rank}{e} \geq 1) \land (d_k = in) \} \\
    \end{array}
  }
  {
    \sigma \vdash \module{Linear}{in, out, bias=True}{E} \Rar e', c \cup c'
  }
\end{align*}

\section*{Activations}
\subsection*{\texttt{torch.nn.ReLU}, \texttt{torch.nn.ReLU6}, \texttt{torch.relu}, \texttt{torch.nn.functional.relu}}
\prepostc{torch.nn.ReLU(inplace=True)(x)}{
  \includegraphics[height=12em]{resources/conv2d.png}
}{
}{
  \begin{itemizec}
    \item $|y| = |x|$ (same shape)
  \end{itemizec}
}{
  \begin{itemizec}
    \item $inplace$ 옵션은 shape에 영향을 주지 않습니다.
    \item \texttt{ReLU6}도 \texttt{ReLU}와 똑같은 방식으로 shape 계산
    \item Bulitins인 \texttt{torch.relu}와 \texttt{torch.nn.functional.relu}는
    같은거
  \end{itemizec}
}
\begin{align*}
  \forall \mtt{ft} \in \{ \mtt{ReLU}, \mtt{ReLU6} \}, \bigspace
  \frac
  {
    \begin{array}{l}
      \sigma \vdash E \Rar e, c
    \end{array}
  }
  {
    \sigma \vdash \module{ft}{inplace=True}{E} \Rar e, c
  }
\end{align*}
\begin{align*}
  \frac
  {
    \begin{array}{l}
      \sigma \vdash E \Rar e, c
    \end{array}
  }
  {
    \sigma \vdash \op{relu}{E, inplace=True} \Rar e, c
  }
\end{align*}

\section*{Technique}
\subsection*{\texttt{torch.nn.Dropout}, \texttt{torch.dropout}, \texttt{torch.nn.functional.dropout}}
\prepostc{torch.nn.Dropout(...)(x)}{
  \includegraphics[height=12em]{resources/conv2d.png}
}{
}{
  \begin{itemizec}
    \item $|y| = |x|$ (same shape)
  \end{itemizec}
}{
  \begin{itemizec}
    \item 모든 옵션은 shape에 영향을 주지 않습니다.
    \item Bulitins인 \texttt{torch.dropout}와
    \texttt{torch.nn.functional.dropout}는 서로 역할이 같습니다.
  \end{itemizec}
}
\begin{align*}
  \frac
  {
    \begin{array}{l}
      \sigma \vdash E \Rar e, c
    \end{array}
  }
  {
    \sigma \vdash \module{Dropout}{...}{E} \Rar e, c
  }
\end{align*}
\begin{align*}
  \frac
  {
    \begin{array}{l}
      \sigma \vdash E \Rar e, c
    \end{array}
  }
  {
    \sigma \vdash \op{dropout}{E, ...} \Rar e, c
  }
\end{align*}

\section*{Wrapper}
\subsection*{\texttt{torch.nn.Sequential}}
\prepost{torch.nn.Sequential(l1, l2, l3, ..., ln)(x)}{
  \includegraphics[height=12em]{resources/conv2d.png}
}{
  \begin{itemizec}
    \item 순차적으로 shape이 맞아떨어져야함
  \end{itemizec}
}{
  \begin{itemizec}
    \item $|y| = |l_n \circ l_{n-1} \circ \cdots \circ l_1(x)|$
  \end{itemizec}
}
\begin{align*}
  \frac
  {
    \begin{array}{l}
      \sigma \vdash l_n \circ l_{n-1} \circ \cdots l_1 (E) \Rar e, c
    \end{array}
  }
  {
    \sigma \vdash \module{Sequential}{l_1, l_2, \dots, l_n}{E} \Rar e, c
  }
\end{align*}

\end{document}
